# Comparing `tmp/walledeval-0.0.1.dev0.tar.gz` & `tmp/walledeval-0.0.1.dev1.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "walledeval-0.0.1.dev0.tar", max compression
+gzip compressed data, was "walledeval-0.0.1.dev1.tar", max compression
```

## Comparing `walledeval-0.0.1.dev0.tar` & `walledeval-0.0.1.dev1.tar`

### file list

```diff
@@ -1,8 +1,8 @@
--rw-r--r--   0        0        0     1086 2024-04-28 13:50:11.030202 walledeval-0.0.1.dev0/LICENSE
--rw-r--r--   0        0        0     1360 2024-05-14 15:48:23.250385 walledeval-0.0.1.dev0/pyproject.toml
--rw-r--r--   0        0        0     2669 2024-05-14 15:49:02.068724 walledeval-0.0.1.dev0/README.md
--rw-r--r--   0        0        0      330 2024-05-14 15:49:10.331458 walledeval-0.0.1.dev0/walledeval/__init__.py
--rw-r--r--   0        0        0     2850 2024-05-14 15:49:12.012767 walledeval-0.0.1.dev0/walledeval/benchmark.py
--rw-r--r--   0        0        0     3777 2024-05-14 15:49:13.328203 walledeval-0.0.1.dev0/walledeval/judge.py
--rw-r--r--   0        0        0     1931 2024-05-14 15:46:06.846587 walledeval-0.0.1.dev0/walledeval/llm.py
--rw-r--r--   0        0        0     4013 1970-01-01 00:00:00.000000 walledeval-0.0.1.dev0/PKG-INFO
+-rw-r--r--   0        0        0     1086 2024-04-28 13:50:11.030202 walledeval-0.0.1.dev1/LICENSE
+-rw-r--r--   0        0        0     1361 2024-05-15 11:19:14.505914 walledeval-0.0.1.dev1/pyproject.toml
+-rw-r--r--   0        0        0     3264 2024-05-14 15:54:35.484696 walledeval-0.0.1.dev1/README.md
+-rw-r--r--   0        0        0      330 2024-05-14 15:49:10.331458 walledeval-0.0.1.dev1/walledeval/__init__.py
+-rw-r--r--   0        0        0     2850 2024-05-14 15:49:12.012767 walledeval-0.0.1.dev1/walledeval/benchmark.py
+-rw-r--r--   0        0        0     3777 2024-05-14 15:49:13.328203 walledeval-0.0.1.dev1/walledeval/judge.py
+-rw-r--r--   0        0        0     1942 2024-05-15 11:13:56.734825 walledeval-0.0.1.dev1/walledeval/llm.py
+-rw-r--r--   0        0        0     4608 1970-01-01 00:00:00.000000 walledeval-0.0.1.dev1/PKG-INFO
```

### Comparing `walledeval-0.0.1.dev0/LICENSE` & `walledeval-0.0.1.dev1/LICENSE`

 * *Files identical despite different names*

### Comparing `walledeval-0.0.1.dev0/pyproject.toml` & `walledeval-0.0.1.dev1/pyproject.toml`

 * *Files 9% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 [tool.poetry]
 name = "walledeval"
-version = "0.0.1dev"
+version = "0.0.1dev1"
 description = "An open-source toolkit to test LLMs against jailbreaks and unprecedented harms."
 license = "MIT"
 authors = ["Rishabh Bhardwaj", "Prannaya Gupta <prannayagupta@programmer.net>"]
 readme = "README.md"
 repository = "https://github.com/walledai/walledeval"
 keywords = ["NLP", "deep learning", "transformer", "language model", "jailbreaking", "red-teaming"]
 classifiers = [
```

### Comparing `walledeval-0.0.1.dev0/README.md` & `walledeval-0.0.1.dev1/README.md`

 * *Files 18% similar despite different names*

```diff
@@ -1,11 +1,16 @@
 # walledeval
 
 > _Test LLMs against jailbreaks and unprecedented harms_
 
+<!-- [![Python Package tests status](https://github.com/three-body-analysis/tris/actions/workflows/python-package.yml/badge.svg)](https://github.com/three-body-analysis/tris/actions?query=workflow%3Apython-package) -->
+<!-- [![Docs CI status](https://github.com/three-body-analysis/tris/actions/workflows/docs.yml/badge.svg)](https://three-body-analysis.github.io/tris/) -->
+[![PyPI Latest Release](https://img.shields.io/pypi/v/walledeval.svg)](https://pypi.org/project/walledeval/)
+<!-- [![PyPI Downloads](https://static.pepy.tech/badge/walledeval)](https://pepy.tech/project/walledeval) -->
+
 WalledEval is a simple library to test LLM safety by identifying if text generated by the LLM is indeed safe. We purposefully test benchmarks with negative information and toxic prompts to see if it is able to flag prompts of malice.
 
 ## Basic Usage
 
 ### LLMs (`walledeval.llm`)
 
 We support the following LLM types:
```

### Comparing `walledeval-0.0.1.dev0/walledeval/benchmark.py` & `walledeval-0.0.1.dev1/walledeval/benchmark.py`

 * *Files identical despite different names*

### Comparing `walledeval-0.0.1.dev0/walledeval/judge.py` & `walledeval-0.0.1.dev1/walledeval/judge.py`

 * *Files identical despite different names*

### Comparing `walledeval-0.0.1.dev0/walledeval/llm.py` & `walledeval-0.0.1.dev1/walledeval/llm.py`

 * *Files 2% similar despite different names*

```diff
@@ -36,15 +36,15 @@
             **kwargs
         )
     
     def generate(self, text: str) -> str:
         text = self.pipeline([
             {"role": "system", "content": self.system_prompt},
             {"role": "user", "content": text},
-        ], max_new_tokens = 128)[0]['generated_text'][-1]
+        ], max_new_tokens = 128)[0]['generated_text'][-1]["content"]
         return text
     
 class Claude(LLM):
     def __init__(self, api_key: str, system_prompt: str = ""):
         super().__init__("Claude 3 Opus", system_prompt)
         self.client = Anthropic(api_key=api_key)
```

### Comparing `walledeval-0.0.1.dev0/PKG-INFO` & `walledeval-0.0.1.dev1/PKG-INFO`

 * *Files 13% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: walledeval
-Version: 0.0.1.dev0
+Version: 0.0.1.dev1
 Summary: An open-source toolkit to test LLMs against jailbreaks and unprecedented harms.
 Home-page: https://github.com/walledai/walledeval
 License: MIT
 Keywords: NLP,deep learning,transformer,language model,jailbreaking,red-teaming
 Author: Rishabh Bhardwaj
 Requires-Python: >=3.10,<4.0
 Classifier: Development Status :: 1 - Planning
@@ -28,14 +28,19 @@
 Project-URL: Repository, https://github.com/walledai/walledeval
 Description-Content-Type: text/markdown
 
 # walledeval
 
 > _Test LLMs against jailbreaks and unprecedented harms_
 
+<!-- [![Python Package tests status](https://github.com/three-body-analysis/tris/actions/workflows/python-package.yml/badge.svg)](https://github.com/three-body-analysis/tris/actions?query=workflow%3Apython-package) -->
+<!-- [![Docs CI status](https://github.com/three-body-analysis/tris/actions/workflows/docs.yml/badge.svg)](https://three-body-analysis.github.io/tris/) -->
+[![PyPI Latest Release](https://img.shields.io/pypi/v/walledeval.svg)](https://pypi.org/project/walledeval/)
+<!-- [![PyPI Downloads](https://static.pepy.tech/badge/walledeval)](https://pepy.tech/project/walledeval) -->
+
 WalledEval is a simple library to test LLM safety by identifying if text generated by the LLM is indeed safe. We purposefully test benchmarks with negative information and toxic prompts to see if it is able to flag prompts of malice.
 
 ## Basic Usage
 
 ### LLMs (`walledeval.llm`)
 
 We support the following LLM types:
```


# Comparing `tmp/atlasai_mlhub_client-0.0.1-py3-none-any.whl.zip` & `tmp/atlasai_mlhub_client-0.0.2-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,16 +1,17 @@
-Zip file size: 8297 bytes, number of entries: 14
--rw-rw-r--  2.0 unx      198 b- defN 24-Apr-16 16:50 atlasai/mlhub/client/__init__.py
--rw-rw-r--  2.0 unx      967 b- defN 24-Apr-16 16:50 atlasai/mlhub/client/authenticate.py
--rw-rw-r--  2.0 unx      189 b- defN 24-Apr-16 16:50 atlasai/mlhub/client/constants.py
--rw-rw-r--  2.0 unx     3238 b- defN 24-Apr-16 16:50 atlasai/mlhub/client/discovery.py
--rw-rw-r--  2.0 unx     4266 b- defN 24-Apr-16 16:50 atlasai/mlhub/client/evaluate.py
--rw-rw-r--  2.0 unx      416 b- defN 24-Apr-16 16:50 atlasai/mlhub/client/job.py
--rw-rw-r--  2.0 unx      699 b- defN 24-Apr-16 16:50 atlasai/mlhub/client/model.py
--rw-rw-r--  2.0 unx     1681 b- defN 24-Apr-16 16:50 atlasai/mlhub/client/requests.py
--rw-rw-r--  2.0 unx     1732 b- defN 24-Apr-16 16:50 atlasai/mlhub/client/response.py
--rw-rw-r--  2.0 unx      563 b- defN 24-Apr-16 16:50 atlasai/mlhub/client/utils.py
--rw-rw-r--  2.0 unx     1194 b- defN 24-Apr-16 17:06 atlasai_mlhub_client-0.0.1.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 24-Apr-16 17:06 atlasai_mlhub_client-0.0.1.dist-info/WHEEL
--rw-rw-r--  2.0 unx        8 b- defN 24-Apr-16 17:06 atlasai_mlhub_client-0.0.1.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     1228 b- defN 24-Apr-16 17:06 atlasai_mlhub_client-0.0.1.dist-info/RECORD
-14 files, 16471 bytes uncompressed, 6221 bytes compressed:  62.2%
+Zip file size: 17946 bytes, number of entries: 15
+-rw-rw-r--  2.0 unx      796 b- defN 24-May-15 08:27 atlasai/mlhub/client/__init__.py
+-rw-rw-r--  2.0 unx     1565 b- defN 24-May-15 08:27 atlasai/mlhub/client/authenticate.py
+-rw-rw-r--  2.0 unx      846 b- defN 24-May-15 08:27 atlasai/mlhub/client/constants.py
+-rw-rw-r--  2.0 unx     3836 b- defN 24-May-15 08:27 atlasai/mlhub/client/discovery.py
+-rw-rw-r--  2.0 unx     6495 b- defN 24-May-15 08:27 atlasai/mlhub/client/evaluate.py
+-rw-rw-r--  2.0 unx     1032 b- defN 24-May-15 08:27 atlasai/mlhub/client/job.py
+-rw-rw-r--  2.0 unx     1312 b- defN 24-May-15 08:27 atlasai/mlhub/client/model.py
+-rw-rw-r--  2.0 unx     2370 b- defN 24-May-15 08:27 atlasai/mlhub/client/requests.py
+-rw-rw-r--  2.0 unx     6309 b- defN 24-May-15 08:27 atlasai/mlhub/client/response.py
+-rw-rw-r--  2.0 unx     3248 b- defN 24-May-15 08:27 atlasai/mlhub/client/utils.py
+-rw-rw-r--  2.0 unx    11358 b- defN 24-May-15 08:33 atlasai_mlhub_client-0.0.2.dist-info/LICENSE.txt
+-rw-rw-r--  2.0 unx     1306 b- defN 24-May-15 08:33 atlasai_mlhub_client-0.0.2.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 24-May-15 08:33 atlasai_mlhub_client-0.0.2.dist-info/WHEEL
+-rw-rw-r--  2.0 unx        8 b- defN 24-May-15 08:33 atlasai_mlhub_client-0.0.2.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     1338 b- defN 24-May-15 08:33 atlasai_mlhub_client-0.0.2.dist-info/RECORD
+15 files, 41911 bytes uncompressed, 15698 bytes compressed:  62.5%
```

## zipnote {}

```diff
@@ -24,20 +24,23 @@
 
 Filename: atlasai/mlhub/client/response.py
 Comment: 
 
 Filename: atlasai/mlhub/client/utils.py
 Comment: 
 
-Filename: atlasai_mlhub_client-0.0.1.dist-info/METADATA
+Filename: atlasai_mlhub_client-0.0.2.dist-info/LICENSE.txt
 Comment: 
 
-Filename: atlasai_mlhub_client-0.0.1.dist-info/WHEEL
+Filename: atlasai_mlhub_client-0.0.2.dist-info/METADATA
 Comment: 
 
-Filename: atlasai_mlhub_client-0.0.1.dist-info/top_level.txt
+Filename: atlasai_mlhub_client-0.0.2.dist-info/WHEEL
 Comment: 
 
-Filename: atlasai_mlhub_client-0.0.1.dist-info/RECORD
+Filename: atlasai_mlhub_client-0.0.2.dist-info/top_level.txt
+Comment: 
+
+Filename: atlasai_mlhub_client-0.0.2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## atlasai/mlhub/client/__init__.py

```diff
@@ -1,5 +1,19 @@
+# Copyright 2024 AtlasAI PBC. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 from .authenticate import authenticate
 from .constants import DEPLOYMENT_TYPES
 from .evaluate import evaluate, get_job_result
 from .model import get_models, get_model_info
 from .job import get_jobs
```

## atlasai/mlhub/client/authenticate.py

```diff
@@ -1,7 +1,21 @@
+# Copyright 2024 AtlasAI PBC. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import logging
 import os
 
 from furl import furl
 import requests
 
 from . import discovery
```

## atlasai/mlhub/client/constants.py

```diff
@@ -1,13 +1,30 @@
+# Copyright 2024 AtlasAI PBC. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 from types import SimpleNamespace
 
 HTTP = 'http'
 BATCH = 'batch'
 
 DEPLOYMENT_TYPES = SimpleNamespace(
     http=HTTP,
     batch=BATCH
 )
 
 DEFAULT_POLLING_TIMEOUT = 3600
+DEFAULT_PAGE_SIZE = 100
+
+MAX_BODY_SIZE = 30 * 1024 * 1024
 
-POLLING_INTERVAL = 10
+POLLING_INTERVAL = 10
```

## atlasai/mlhub/client/discovery.py

```diff
@@ -1,7 +1,21 @@
+# Copyright 2024 AtlasAI PBC. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import hmac
 import logging
 import os
 from urllib.parse import urlparse
 import warnings
 
 import arrow
```

## atlasai/mlhub/client/evaluate.py

```diff
@@ -1,99 +1,143 @@
+# Copyright 2024 AtlasAI PBC. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import concurrent.futures
+import io
+import json
 import logging
 import os
 import time
 from typing import Union
 
-from .constants import DEPLOYMENT_TYPES, DEFAULT_POLLING_TIMEOUT, POLLING_INTERVAL
+from .constants import DEPLOYMENT_TYPES, DEFAULT_POLLING_TIMEOUT, MAX_BODY_SIZE, POLLING_INTERVAL
 from .requests import get_session
 from .response import JobResultResponse, JobResponse
-from .utils import get_headers, get_model_url
+from .utils import get_base_url, get_headers, get_model_url, get_deployment_url
 
 logger = logging.getLogger(__name__)
 
 def evaluate(
         model: str, version: str, data: dict = None,
         deployment_type: str = DEPLOYMENT_TYPES.http,
         timeout: int = DEFAULT_POLLING_TIMEOUT,
-        wait_for_completion: bool = True
+        wait_for_completion: bool = True,
+        tabular: bool = True,
+        data_type: str = 'json'
 ) -> Union[JobResultResponse, JobResponse]:
     """
     Evaluate a specific model with specific data.
 
     Args:
         model (str): The name of the model you want to evaluate
         version (str): The version of the model you want to evaluate
         deployment_type (str): The type of deployment you want. http or batch.
 
         data (dict): The data to be sent in the request body.
         timeout (int, optional): Maximum time interval to wait for a response
         wait_for_completion (bool, optional, default: true). Wait for the function to poll for results in case of batch.
             Set to false in case you want to do the polling yourself.
+        tabular (bool, default True): How to display the columns if they are list or dict. Tabular format or json
+        data_type (str, default: json): The type of the input data. Can be json or csv.
 
     Returns:
         JobResultResponse: The response object from the evaluation.
         JobResponse: If batch deployment type is true and wait_for_completion is false will return a string with the resource to poll.
 
     """
 
     if not os.environ['MLHUB_URL']:
         raise ValueError('MLHUB_URL must be provided.')
 
-    url = f"{get_model_url(model, version)}/evaluate"
+    url = f"{get_deployment_url(model, version, deployment_type)}/evaluate"
 
-    headers = get_headers()
+    str_data = json.dumps(data) if not isinstance(data, str) else data
 
-    body = {
-        'deployment_type': deployment_type,
-        'version': version,
-        'data': data
-    }
+    if len(str_data) < MAX_BODY_SIZE:
+        body = {'data': data}
+    else:
+        logger.debug(f'Input data exceeds {MAX_BODY_SIZE} size.')
+        if deployment_type != DEPLOYMENT_TYPES.batch:
+            raise ValueError(f'Input data size exceeds {MAX_BODY_SIZE} bytes.'
+                             f' This is allowed only for batch evaluations.')
+        storage_path = upload_data(str_data, data_type)
+        body = {'url': storage_path}
     session = get_session()
-    response = session.post(url, json=body, headers=headers, timeout=timeout)
+    response = session.post(url, json=body, headers=get_headers(), timeout=timeout)
     response.raise_for_status()
 
     if response.status_code == 200:
-        return JobResultResponse.from_dict(**response.json())
+        return JobResultResponse(**response.json(), tabular=tabular)
     elif response.status_code == 202:
         if wait_for_completion:
             return process_polling_response(model, version, response.headers['Location'], timeout=timeout)
         else:
-            return JobResponse(model=model, version=version, job_id=response.headers['Location'])
+            return JobResponse(model=model, version=version, job_id=response.headers['Location'], tabular=tabular)
+
+
+
+def upload_data(data, file_type):
+    logger.debug('Requesting signed url.')
+    session = get_session()
+    url = f"{get_base_url()}/create-signed-url"
+    response = session.post(url, json={'file_type': file_type}, headers=get_headers())
+    response.raise_for_status()
 
+    response_data = response.json()
+    logger.debug('Uploading data to storage.')
+    response = session.put(response_data['signed_url'], data=io.StringIO(data), headers=response_data['headers'])
+    response.raise_for_status()
+    return response_data['storage_path']
 
 
-def get_job_result(data: JobResponse, timeout: int = DEFAULT_POLLING_TIMEOUT):
+def get_job_result(job: JobResponse, timeout: int = DEFAULT_POLLING_TIMEOUT, tabular: bool = True, wait: bool = False):
     """
     Get results for a specific job
 
     Args:
-        data: JobResponse. Object that contains the model, version and resource to poll
+        job: JobResponse. Object that contains the model, version and resource to poll
 
         timeout (int, optional): Maximum time interval to wait for a response
 
+        tabular (bool, default True): How to display the columns if they are list or dict. Tabular format or json
+
+        wait (bool, default False): Wait for the job to finish
+
     Returns:
         JobResultResponse: The response object from the evaluation.
 
     """
     if not os.environ['MLHUB_URL']:
         raise ValueError('MLHUB_URL must be provided.')
 
     session = get_session()
 
     headers = get_headers()
-    url = f"{get_model_url(data.model, data.version)}/job/{data.job_id}"
+    url = f"{get_model_url(job.model, job.version)}/job/{job.job_id}"
+
+    if wait is True:
+        return process_polling_response(job.model, job.version, job.job_id, timeout=timeout)
+
     response = session.get(url, headers=headers, timeout=timeout)
     response.raise_for_status()
-
-    if response.status_code == 200:
-        return JobResultResponse.from_dict(**response.json())
+    return JobResultResponse(**response.json(), tabular=tabular)
 
 
-def process_polling_response(model, version, job_id, timeout=DEFAULT_POLLING_TIMEOUT):
+def process_polling_response(model, version, job_id, timeout=DEFAULT_POLLING_TIMEOUT, tabular=True):
     def poll(_url):
         while True:
             headers = get_headers()
             session = get_session()
             _response = session.get(_url, headers=headers)
             _response.raise_for_status()
 
@@ -117,8 +161,8 @@
             except Exception as e:
                 logger.error(f"Polling failed: {e}")
                 raise e
 
     url = f"{get_model_url(model, version)}/job/{job_id}"
 
     response = poll_until_finished(url)
-    return JobResultResponse.from_dict(**response)
+    return JobResultResponse(**response, tabular=tabular)
```

## atlasai/mlhub/client/job.py

```diff
@@ -1,15 +1,29 @@
+# Copyright 2024 AtlasAI PBC. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import logging
 
+from .constants import DEFAULT_PAGE_SIZE
 from .requests import paginate
-from .response import JobInfoResponse, JobInfoResponses
+from .response import JobInfoResponse
 from .utils import get_model_url
 
 
 logger = logging.getLogger(__name__)
 
-def get_jobs(model, version, limit=100, offset=0):
+def get_jobs(model, version, limit=DEFAULT_PAGE_SIZE, offset=0, tabular=True):
     url = f"{get_model_url(model, version)}/jobs"
 
-    results = paginate(url, limit, offset)
-
-    return JobInfoResponses(jobs=[JobInfoResponse.from_dict(**result) for result in results])
+    for result in paginate(url, limit, offset):
+        yield JobInfoResponse(**result, tabular=tabular)
```

## atlasai/mlhub/client/model.py

```diff
@@ -1,26 +1,40 @@
+# Copyright 2024 AtlasAI PBC. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import logging
 
+from .constants import DEFAULT_PAGE_SIZE
 from .requests import get_session, paginate
-from .response import ModelInfoResponse, ModelResponse, ModelResponses
+from .response import ModelResponse
 from .utils import get_base_url, get_headers, get_model_url
 
 
 logger = logging.getLogger(__name__)
 
-def get_models(limit=100, offset=0):
+def get_models(limit=DEFAULT_PAGE_SIZE, offset=0, tabular=True):
     url = f"{get_base_url()}/models"
 
-    results = paginate(url, limit, offset)
-
-    return ModelResponses(responses=[ModelResponse.from_dict(**result) for result in results])
+    for result in paginate(url, limit, offset):
+        yield ModelResponse(**result, tabular=tabular)
 
 
-def get_model_info(model, version):
+def get_model_info(model, version, tabular=True):
     url = get_model_url(model, version)
 
     session = get_session()
 
     response = session.get(url, headers=get_headers())
     response.raise_for_status()
 
-    return ModelInfoResponse.from_dict(**response.json())
+    return ModelResponse(**response.json(), tabular=tabular)
```

## atlasai/mlhub/client/requests.py

```diff
@@ -1,15 +1,31 @@
+# Copyright 2024 AtlasAI PBC. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 """
 ## Helpers for Requests package
 """
 
 import requests
 from requests.adapters import HTTPAdapter, Retry
+from .constants import DEFAULT_PAGE_SIZE
 from .utils import get_headers
 
+
 STATUS_FORCELIST = tuple([429, 500, 502, 503, 504])
 
 def mount_retry(
     session,
     total=10,
     backoff_factor=0.2,
     allowed_methods=None,
@@ -46,23 +62,26 @@
         backoff_factor=backoff_factor,
         allowed_methods=allowed_methods,
         status_forcelist=status_forcelist,
     )
 
     return sess
 
-def paginate(url, limit=100, offset=0):
-    def _get_results(_url, _limit, _offset):
+def paginate(url, limit=None, offset=0):
+    if limit is None:
+        limit = DEFAULT_PAGE_SIZE
+    def _get_results(_url, _limit, _offset=0):
         _response = session.post(_url, json={'limit': _limit, 'offset': _offset}, headers=get_headers())
         _response.raise_for_status()
         return _response
 
-    results = []
     session = get_session()
     while True:
         response = _get_results(url, limit, offset)
         data = response.json()['data']
+        for result in data:
+            yield result
+
         if not data:
             break
-        results.extend(data)
+
         offset += limit
-    return results
```

## atlasai/mlhub/client/response.py

```diff
@@ -1,81 +1,231 @@
+# Copyright 2024 AtlasAI PBC. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import inspect
-from dataclasses import dataclass
+import pandas as pd
 
-from typing import List
+from .requests import get_session
+from .utils import flatten_nested_json_df
 
-class Response:
-    @classmethod
-    def from_dict(cls, **kwargs):
-        return cls(**{k: v for k, v in kwargs.items() if k in inspect.signature(cls).parameters})
-
-
-@dataclass
-class JobResponse(Response):
-    model: str
-    version: str
-    job_id: str
-
-@dataclass
-class JobResultResponse(Response):
-    status: str
-    predictions: dict
-    info: str
+class SingleResponse:
+    def get_properties(self):
+        return [name for name, member in inspect.getmembers(self.__class__, lambda x: isinstance(x, property))]
 
-    def __str__(self):
-        return f'Predictions: {self.predictions}'
+    def as_df(self):
+        return flatten_nested_json_df(pd.json_normalize(self.as_dict()))
 
-@dataclass
-class JobInfoResponse(Response):
-    id: str
-    job_id: str
-    storage_path: str
-    data: dict
-
-@dataclass
-class JobInfoResponses(Response):
-    jobs: List[JobInfoResponse]
-    def __getitem__(self, index):
-        return self.jobs[index]
+    def as_dict(self):
+        return {prop: getattr(self, '_' + prop) for prop in self.get_properties() if hasattr(self, '_' + prop)}
 
-    def __len__(self):
-        return len(self.jobs)
 
-    def __str__(self):
-        return f'Jobs: {len(self.jobs)}'
+class JobResponse(SingleResponse):
+
+    def __init__(self, model, version, job_id, tabular=True):
+        self._model = model
+        self._version = version
+        self._job_id = job_id
+        self._tabular = tabular
+
+    @property
+    def model(self):
+        return self._model
+
+    @property
+    def version(self):
+        return self._version
+
+    @property
+    def job_id(self):
+        return self._job_id
+
+    def __repr__(self):
+        return f'JobResponse(job_id={self.job_id})'
 
-@dataclass
-class ModelInfoResponse(Response):
-    id: str
-    name: str
-    version: str
-    status: str
-    deployment_type: str
-    create_date: str
-    signature: dict
-    input_example: dict
-    metrics: dict
-    def __str__(self):
-        return f'Version {self.version} of {self.name} deployed in {self.deployment_type}'
 
-@dataclass
-class ModelResponse(Response):
-    id: str
-    name: str
-    version: str
-    deployment_type: str
-    create_date: str
+class JobResultResponse(SingleResponse):
+    def __init__(self,
+        status, info, predictions=None, url=None, tabular=True
+    ):
+        self._status = status
+        self._info = info
+        self._tabular = tabular
+        self._predictions = predictions
+        self._url = url
+        if url:
+            self._predictions = self.get_data_from_path(url)
+
+
+    @property
+    def status(self):
+        return self._status
+
+    @property
+    def info(self):
+        return self._info
+
+    @property
+    def predictions(self):
+        if self._tabular is False or not isinstance(self._predictions, list):
+            return self._predictions
+        return pd.DataFrame(self._predictions, columns=['Predictions'])
+
+
+    def get_data_from_path(self, url):
+        session = get_session()
+        response = session.get(url)
+        response.raise_for_status()
+        return response.json()
 
     def __str__(self):
-        return f'Version {self.version} of {self.name} deployed in {self.deployment_type}'
+        return f'Status: {self.status}'
 
-@dataclass
-class ModelResponses(Response):
-    responses: List[ModelResponse]
-    def __getitem__(self, index):
-        return self.responses[index]
+    def __repr__(self):
+        return f'JobResultResponse(status={self.status})'
 
-    def __len__(self):
-        return len(self.responses)
+class JobInfoResponse(SingleResponse):
+    def __init__(self, id, job_id, user_id, deployment_type, data, tabular=True):
+        self._id = id
+        self._job_id = job_id
+        self._user_id = user_id
+        self._deployment_type = deployment_type
+        self._data = data
+        self._tabular = tabular
+
+    @property
+    def id(self):
+        return self._id
+
+    @property
+    def job_id(self):
+        return self._job_id
+
+    @property
+    def user_id(self):
+        return self._user_id
+
+    @property
+    def deployment_type(self):
+        return self._deployment_type
+
+    @property
+    def data(self):
+        if self._tabular is False:
+            return self._data
+        return flatten_nested_json_df(pd.json_normalize(self._data or []))
+
+    def __repr__(self):
+        return f'JobInfoResponse(job_id={self.job_id})'
+
+
+class ModelResponse(SingleResponse):
+
+    def __init__(self,
+        id, name, version, tags, aliases, signature, input_example,
+        metrics, retired, retired_date, create_date, tabular=True
+    ):
+        self._id = id
+        self._name = name
+        self._version = version
+        self._retired = retired
+        self._retired_date = retired_date
+        self._create_date = create_date
+        self._tabular = tabular
+        self._tags = tags
+        self._aliases = aliases
+        self._inputs = signature.get('inputs', [])
+        self._outputs = signature.get('outputs', [])
+        self._params = signature.get('params', [])
+        self._input_example = input_example
+        self._metrics = metrics
 
     def __str__(self):
-        return f'Models: {len(self.responses)}'
+        return f'Version {self.version} of {self.name}'
+
+    def __repr__(self):
+        return f'ModelResponse(name={self.name}, version={self.version})'
+
+    @property
+    def id(self):
+        return self._id
+
+    @property
+    def name(self):
+        return self._name
+
+    @property
+    def version(self):
+        return self._version
+
+    @property
+    def retired(self):
+        return self._retired
+
+    @property
+    def retired_date(self):
+        return self._retired_date
+
+    @property
+    def create_date(self):
+        return self._create_date
+
+    @property
+    def metrics(self):
+        if self._tabular is False:
+            return self._metrics
+        return pd.DataFrame(self._metrics, index=[0])
+
+    @property
+    def tags(self):
+        if self._tabular is False:
+            return self._tags
+        return pd.DataFrame(self._tags or {}, index=[0])
+
+    @property
+    def aliases(self):
+        if self._tabular is False:
+            return self._aliases
+        return pd.DataFrame(self._aliases or [])
+
+    @property
+    def inputs(self):
+        if self._tabular is False:
+            return self._inputs
+        return pd.json_normalize(self._inputs or [])
+
+    @property
+    def outputs(self):
+        if self._tabular is False:
+            return self._outputs
+        return pd.json_normalize(self._outputs or [])
+
+    @property
+    def params(self):
+        if self._tabular is False:
+            return self._params
+        return pd.json_normalize(self._params or [])
+
+    @property
+    def input_example(self):
+        if self._tabular is False:
+            return self._input_example
+        return pd.json_normalize(self._input_example or [])
+
+    @property
+    def signature(self):
+        if self._tabular is False:
+            return {'inputs': self.inputs, 'outputs': self.outputs, 'params': self.params}
+        inputs, outputs, params = self.inputs, self.outputs, self.params
+        inputs['_type'], outputs['_type'], params['_type'] = 'input', 'output', 'param'
+
+        return pd.concat([inputs, outputs, params], ignore_index=True)
```

## atlasai/mlhub/client/utils.py

```diff
@@ -1,8 +1,23 @@
+# Copyright 2024 AtlasAI PBC. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
 import os
+import pandas as pd
 
 def validate_request_headers(headers):
     if not headers.get('Authorization'):
         raise Exception('No Authorization token found. Authenticate first')
 
 
 def get_headers():
@@ -13,9 +28,68 @@
 
     validate_request_headers(headers)
     return headers
 
 def get_model_url(model, version):
     return f"{get_base_url()}/model/{model}/version/{version}"
 
+def get_deployment_url(model, version, deployment_type):
+    return f"{get_model_url(model, version)}/deployment/{deployment_type}"
+
 def get_base_url():
     return f"{os.environ['MLHUB_URL']}"
+
+
+def flatten_nested_json_df(df, flatten_depth=-1, flatten_columns=None, should_drop=True):
+    if flatten_depth == 0:
+        return df
+
+    flatten_counter = 0
+    if flatten_columns is None:
+        flatten_columns = df.keys()
+    elif isinstance(flatten_columns, str):
+        flatten_columns = [flatten_columns]
+
+    def should_flatten():
+        return flatten_depth == -1 or flatten_counter < flatten_depth
+
+    def is_flattenable(col):
+        return col.split('.')[0] in flatten_columns
+
+    def get_all_columns_of_type(_type, current_index=None):
+        s = ((df if current_index is None else df[current_index]).map(type) == _type).any()
+        res = s[s].index.tolist()
+        if _type == dict:
+            res = [column for column in res if is_flattenable(column)]
+        return res
+
+    list_columns = get_all_columns_of_type(list)
+    dict_columns = get_all_columns_of_type(dict)
+    columns_to_drop = []
+    while should_flatten() and (len(list_columns) > 0 or len(dict_columns) > 0):
+        new_columns = []
+        to_expand = []
+
+        for col in dict_columns:
+            horiz_exploded = pd.json_normalize(df[col]).add_prefix(f'{col}.')
+            horiz_exploded.index = df.index
+            to_expand.append(horiz_exploded)
+            new_columns.extend(horiz_exploded.columns)
+
+        if dict_columns:
+            columns_to_drop.extend(dict_columns)
+
+        for col in list_columns:
+            horiz_exploded = pd.json_normalize(df[col]).add_prefix(f'{col}.')
+            to_expand.append(horiz_exploded)
+            new_columns.extend(horiz_exploded.columns)
+
+        if to_expand:
+            df = pd.concat([df, *to_expand], axis=1)
+
+        list_columns = get_all_columns_of_type(list, new_columns)
+        dict_columns = get_all_columns_of_type(dict, new_columns)
+        flatten_counter += 1
+
+    if columns_to_drop and should_drop:
+        df = df.drop(columns=columns_to_drop)
+    return df
```

